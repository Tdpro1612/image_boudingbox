{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Week 2 - Cat Face Localization Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "41k00snHwH0y",
        "gUUlSxYzwH1H",
        "V1tfjsRCwH1U",
        "o5tN6Bj-wH1a",
        "ublZeGoEwH1h",
        "TEynl4n-wH1y",
        "lqmDPEmVb1Nz"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j-tyjLYwH0B"
      },
      "source": [
        "# Object Localization Exercise\n",
        "\n",
        "@Class: Advanced Computer Vision\n",
        "\n",
        "@Organization: VietAI\n",
        "\n",
        "@Description: This exercise is to localize cat face in given images.\n",
        "\n",
        "Student Infomation\n",
        "- Name : [Fill in your fullname here]\n",
        "- Email  : [Fill in your email]\n",
        "- Phone : [Fill in your phone]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_bomdNKxdsP"
      },
      "source": [
        "## Mounting to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiCnK2v3weiY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZxjMtYwipn"
      },
      "source": [
        "%cd 'drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNc2LFAR0Ot3"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCtSyE3DwjiY"
      },
      "source": [
        "if not os.path.exists(\"cat_face_exercise\"):\n",
        "    os.makedirs(\"cat_face_exercise\")\n",
        "%cd 'cat_face_exercise'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO2tybTF0fLs"
      },
      "source": [
        "## Downloading dataset\n",
        "\n",
        "The original dataset can be found here. In the scope of this exercise, we use its cleaned version. The dataset contains:\n",
        "* train.csv : .csv file of $8996$ rows, containing image names and coordinates of cat faces in format (x0, y0, width, height)\n",
        "* test.csv : .csv file of $1000$ rows, containing image names\n",
        "* images/ : a folder contains $9996$ images with size of $256 \\times 256$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiidyfjFxqk6"
      },
      "source": [
        "if not os.path.exists(\"images\"):\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    gdd.download_file_from_google_drive(file_id='1WYD6F0utLMaRtdfBqE6i8cpGruMpWnXz', dest_path='../cat_face_exercise/data.zip', unzip=True)\n",
        "    !rm -rf data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "1hVdKDDTwH0D"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_qnBS66HwH0I"
      },
      "source": [
        "TRAIN_FILE = \"train.csv\"\n",
        "TEST_FILE = \"test.csv\"\n",
        "IMAGE_DIR = \"images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZKk1vNW0wH0Q"
      },
      "source": [
        "df = pd.read_csv(TRAIN_FILE)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zcsJV0YTwH0Z"
      },
      "source": [
        "test_df = pd.read_csv(TEST_FILE)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kH5Rh8L7wH0m"
      },
      "source": [
        "train_df, val_df = train_test_split(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5k89gil3wH0q"
      },
      "source": [
        "print(len(df))\n",
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "jZgG0isJwH0u"
      },
      "source": [
        "class Config:\n",
        "    \n",
        "    seed = 2020\n",
        "    \n",
        "    img_width = 256\n",
        "    img_height = 256\n",
        "    \n",
        "    num_classes = 4\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 2    \n",
        "    lr = 1e-5\n",
        "    \n",
        "    verbose = 1\n",
        "    \n",
        "    best_checkpoint_path = 'best.h5'\n",
        "    latest_checkpoint_path = 'latest.h5'\n",
        "    \n",
        "config = Config()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41k00snHwH0y"
      },
      "source": [
        "## TODO 1: Data Loader\n",
        " You need to do the augmentation when loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AlYHnETHwH0z"
      },
      "source": [
        "class ImageGenerator:\n",
        "    \n",
        "    def create(image_df, augument=True, is_train=True):\n",
        "        while True:\n",
        "            \n",
        "            if is_train:\n",
        "                image_df = shuffle(image_df, random_state=config.seed)\n",
        "                \n",
        "            for start in range(0, len(image_df), config.batch_size):\n",
        "                end = min(start + config.batch_size, len(image_df))\n",
        "                batch_images = []\n",
        "                X_train_batch = image_df.iloc[start:end]\n",
        "                \n",
        "                if is_train:\n",
        "                    batch_labels = np.zeros((len(X_train_batch), 4))\n",
        "                \n",
        "                for i in range(len(X_train_batch)):\n",
        "                    # load image\n",
        "                    image_path = os.path.join(IMAGE_DIR, X_train_batch.iloc[i]['ImageId'])\n",
        "                    image = cv2.imread(image_path)\n",
        "                    \n",
        "                    if is_train:\n",
        "                        x0 = X_train_batch.iloc[i]['x0']\n",
        "                        y0 = X_train_batch.iloc[i]['y0']\n",
        "                        w = X_train_batch.iloc[i]['width']\n",
        "                        h = X_train_batch.iloc[i]['height']\n",
        "                    \n",
        "                        # augment data\n",
        "                        if augument:\n",
        "                            # TODO 1: augmentation\n",
        "                            pass\n",
        "\n",
        "                        batch_labels[i][0] = y0 / 256\n",
        "                        batch_labels[i][1] = x0 / 256\n",
        "                        batch_labels[i][2] = h / 256\n",
        "                        batch_labels[i][3] = w / 256\n",
        "\n",
        "                    batch_images.append(image / 255)\n",
        "                    \n",
        "                if is_train:\n",
        "                    yield np.array(batch_images, np.float32), batch_labels\n",
        "                else:\n",
        "                    yield np.array(batch_images, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OoijgjiYwH0_"
      },
      "source": [
        "train_generator = ImageGenerator.create(\n",
        "    train_df,\n",
        "    augument=True\n",
        ")\n",
        "\n",
        "val_generator = ImageGenerator.create(\n",
        "    val_df,\n",
        "    augument=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUUlSxYzwH1H"
      },
      "source": [
        "## TODO 2: Build your own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sjKGtl-AwH1H"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # TODO 2: build your own model\n",
        "])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3_ujzJcIwH1Q"
      },
      "source": [
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=config.lr)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DCus4meQwH1S"
      },
      "source": [
        "best_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.best_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "latest_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.latest_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=False, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", \n",
        "    mode=\"min\", \n",
        "    patience=10\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    patience=2,\n",
        "    factor=0.2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-9\n",
        ")\n",
        "\n",
        "callbacks_list = [\n",
        "    best_checkpoint,\n",
        "    latest_checkpoint,\n",
        "    reduce_lr,\n",
        "    early\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1tfjsRCwH1U"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OuhoNzKMwH1V"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch= np.ceil(float(len(train_df)) / config.batch_size),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= np.ceil(float(len(val_df)) / config.batch_size),\n",
        "    epochs=config.epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=config.verbose\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5tN6Bj-wH1a"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7fHrYpuMwH1a"
      },
      "source": [
        "test_generator = ImageGenerator.create(\n",
        "    test_df,\n",
        "    augument=False,\n",
        "    is_train=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp3W1AxCdQDN"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K8KK0OOdHN_"
      },
      "source": [
        "pred_model = tf.keras.models.load_model(config.best_checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_z3um184wH1b"
      },
      "source": [
        "predict = pred_model.predict(test_generator,\n",
        "                             steps=np.ceil(float(len(test_df)) / config.batch_size),\n",
        "                             verbose=config.verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "57tFLzOCwH1d"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JmdYiDWjwH1g"
      },
      "source": [
        "predict = predict*256\n",
        "predict = predict.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ublZeGoEwH1h"
      },
      "source": [
        "## Create submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SbsMjqK_wH1h"
      },
      "source": [
        "def clip(val, minval, maxval):\n",
        "    \"\"\"Clips a value between min and max (both including).\"\"\"\n",
        "    if val < minval:\n",
        "        return minval\n",
        "    elif val > maxval:\n",
        "        return maxval\n",
        "    else:\n",
        "        return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zElJX0_qwH1o"
      },
      "source": [
        "# clip coordinates to be inside image\n",
        "for box in predict:\n",
        "    y0, x0, height, width = box\n",
        "    \n",
        "    y1 = y0 + height\n",
        "    x1 = x0 + width\n",
        "    \n",
        "    x0 = clip(x0, 0, 255)\n",
        "    x1 = clip(x1, 0, 255)\n",
        "    y0 = clip(y0, 0, 255)\n",
        "    y1 = clip(y1, 0, 255)\n",
        "    \n",
        "    if y0 > y1:\n",
        "        y0, y1 = y1, y0\n",
        "    if x0 > x1:\n",
        "        x0, x1 = x1, x0\n",
        "\n",
        "    height = y1 - y0\n",
        "    width = x1 - x0\n",
        "    \n",
        "    box[0] = y0\n",
        "    box[1] = x0\n",
        "    box[2] = height\n",
        "    box[3] = width"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pS12pjDVwH1q"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "71FNvFYlwH1t"
      },
      "source": [
        "submissions = pd.DataFrame()\n",
        "submissions[\"ImageId\"] = test_df[\"ImageId\"]\n",
        "submissions[\"y0\"] = predict[:, 0]\n",
        "submissions[\"x0\"] = predict[:, 1]\n",
        "submissions[\"height\"] = predict[:, 2]\n",
        "submissions[\"width\"] = predict[:, 3]\n",
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J3gr9GtOwH1x"
      },
      "source": [
        "submissions.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEynl4n-wH1y"
      },
      "source": [
        "## TODO 3: Visualize prediction\n",
        "\n",
        "You need to visualize predicted bounding box on given test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q6xR4NTowH1z"
      },
      "source": [
        "N = len(test_df)\n",
        "N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kyXM-bMJwH10"
      },
      "source": [
        "def draw_box(model, image_path):\n",
        "    # TODO 3: draw predicted bounding box on given test images\n",
        "    pass\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GffI3bBEwH12"
      },
      "source": [
        "num_sample = 10\n",
        "\n",
        "for idx in range(num_sample):\n",
        "    idx = random.randint(0, N - 1)\n",
        "    image_name = test_df[\"ImageId\"].iloc[idx]\n",
        "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
        "    \n",
        "    draw_box(pred_model, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqmDPEmVb1Nz"
      },
      "source": [
        "## TODO 4: Customize your model\n",
        "\n",
        "You need to build a model that can check if cat face exists in given images. If exists, then predict the cat face coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk68sbX9vJ2T"
      },
      "source": [
        "# TODO 4:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YcYUfPA3Ocv"
      },
      "source": [
        "# What to submit?\n",
        "\n",
        "Please send a .zip file to my email: thanglecao0412@gmail.com with the subject [VietAI Detection Exercise - Your name]. \n",
        "The .zip file includes\n",
        "- This notebook when you finish\n",
        "- Your submission file (.csv) on test dataset. Note that the submission file has the same format as **train.csv**\n",
        "- Your best model checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0LLz9746tfM"
      },
      "source": [
        "# Deadline: 23h55 pm 23-09-2020"
      ]
    }
  ]
}