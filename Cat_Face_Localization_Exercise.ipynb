{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat Face Localization Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UaB0jUXsy8j"
      },
      "source": [
        "# Object Localization Exercise\n",
        "\n",
        "@Class: Advanced Computer Vision\n",
        "\n",
        "@Organization: VietAI\n",
        "\n",
        "@Description: This exercise is to localize cat face in given images.\n",
        "\n",
        "Student Infomation\n",
        "- Name : [Nguyen Khoa Nguyen]\n",
        "- Email  : [hangthieulong508@gmail.com]\n",
        "- Phone : [0385127504]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53GOG3q5vEGX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_RFsb_cacFY"
      },
      "source": [
        "## Mounting to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAKtxD_pu-H3",
        "outputId": "996cba59-87df-4791-d9e5-5e48f3c4167e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyA6LEduasVA"
      },
      "source": [
        "##Check Colab GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4brLgYDbFoa",
        "outputId": "dd360c0f-9bee-4fbe-fab6-1ff4ff5a342d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 21 03:59:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tqRG_2-er5M"
      },
      "source": [
        "## Downloading dataset\n",
        "\n",
        "The original dataset can be found here. In the scope of this exercise, we use its cleaned version. The dataset contains:\n",
        "* train.csv : .csv file of $8996$ rows, containing image names and coordinates of cat faces in format (x0, y0, width, height)\n",
        "* test.csv : .csv file of $1000$ rows, containing image names\n",
        "* images/ : a folder contains $9996$ images with size of $256 \\times 256$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUs6p2SXfU3s"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmAn0UqkvLGx"
      },
      "source": [
        "TRAIN_FILE = \"/content/drive/My Drive/cat_face_exercise/train.csv\"\n",
        "TEST_FILE = \"/content/drive/My Drive/cat_face_exercise/test.csv\"\n",
        "IMAGE_DIR = \"/content/drive/My Drive/cat_face_exercise/images\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zeIiPVvNjQ",
        "outputId": "be09eb46-d42d-4cc9-a675-fdb4929d5365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv(TRAIN_FILE)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>y0</th>\n",
              "      <th>x0</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>04106.jpg</td>\n",
              "      <td>9</td>\n",
              "      <td>92</td>\n",
              "      <td>159</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03683.jpg</td>\n",
              "      <td>16</td>\n",
              "      <td>52</td>\n",
              "      <td>184</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>04598.jpg</td>\n",
              "      <td>12</td>\n",
              "      <td>86</td>\n",
              "      <td>97</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06239.jpg</td>\n",
              "      <td>49</td>\n",
              "      <td>53</td>\n",
              "      <td>92</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01965.jpg</td>\n",
              "      <td>10</td>\n",
              "      <td>65</td>\n",
              "      <td>170</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ImageId  y0  x0  height  width\n",
              "0  04106.jpg   9  92     159    110\n",
              "1  03683.jpg  16  52     184    165\n",
              "2  04598.jpg  12  86      97     63\n",
              "3  06239.jpg  49  53      92    149\n",
              "4  01965.jpg  10  65     170    122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAP-z-aovQlZ",
        "outputId": "36af9ae2-5b5e-49b7-9a50-669f8d78f0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df = pd.read_csv(TEST_FILE)\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03227.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02572.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>05307.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>09114.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07639.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ImageId\n",
              "0  03227.jpg\n",
              "1  02572.jpg\n",
              "2  05307.jpg\n",
              "3  09114.jpg\n",
              "4  07639.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U6AVlOYvSPG"
      },
      "source": [
        "train_df, val_df = train_test_split(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MekwqWVvWNv",
        "outputId": "bdf9ce01-8e7c-4be6-cd6f-ef2a850b7af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(len(df))\n",
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8996\n",
            "6747\n",
            "2249\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_WduMcSvXta"
      },
      "source": [
        "class Config:\n",
        "    \n",
        "    seed = 2020\n",
        "    \n",
        "    img_width = 256\n",
        "    img_height = 256\n",
        "    \n",
        "    num_classes = 4\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 2    \n",
        "    lr = 1e-5\n",
        "    \n",
        "    verbose = 1\n",
        "    \n",
        "    best_checkpoint_path = 'best.h5'\n",
        "    latest_checkpoint_path = 'latest.h5'\n",
        "    \n",
        "config = Config()   "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnfTA-GBJqYl"
      },
      "source": [
        "## TODO 1: Data Loader\n",
        " You need to do the augmentation when loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DMNhaweJoaE"
      },
      "source": [
        "class ImageGenerator:\n",
        "    \n",
        "    def create(image_df, augument=True, is_train=True):\n",
        "        while True:\n",
        "            \n",
        "            if is_train:\n",
        "                image_df = shuffle(image_df, random_state=config.seed)\n",
        "                \n",
        "            for start in range(0, len(image_df), config.batch_size):\n",
        "                end = min(start + config.batch_size, len(image_df))\n",
        "                batch_images = []\n",
        "                X_train_batch = image_df.iloc[start:end]\n",
        "                \n",
        "                if is_train:\n",
        "                    batch_labels = np.zeros((len(X_train_batch), 4))\n",
        "                \n",
        "                for i in range(len(X_train_batch)):\n",
        "                    # load image\n",
        "                    image_path = os.path.join(IMAGE_DIR, X_train_batch.iloc[i]['ImageId'])\n",
        "                    image = cv2.imread(image_path)\n",
        "                    \n",
        "                    if is_train:\n",
        "                        x0 = X_train_batch.iloc[i]['x0']\n",
        "                        y0 = X_train_batch.iloc[i]['y0']\n",
        "                        w = X_train_batch.iloc[i]['width']\n",
        "                        h = X_train_batch.iloc[i]['height']\n",
        "                    \n",
        "                        # augment data\n",
        "                        if augument:\n",
        "                            # TODO 1: augmentation\n",
        "                            pass\n",
        "\n",
        "                        batch_labels[i][0] = y0 / 256\n",
        "                        batch_labels[i][1] = x0 / 256\n",
        "                        batch_labels[i][2] = h / 256\n",
        "                        batch_labels[i][3] = w / 256\n",
        "\n",
        "                    batch_images.append(image / 255)\n",
        "                    \n",
        "                if is_train:\n",
        "                    yield np.array(batch_images, np.float32), batch_labels\n",
        "                else:\n",
        "                    yield np.array(batch_images, np.float32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPIzcM_Uvdx0"
      },
      "source": [
        "train_generator = ImageGenerator.create(\n",
        "    train_df,\n",
        "    augument=True\n",
        ")\n",
        "\n",
        "val_generator = ImageGenerator.create(\n",
        "    val_df,\n",
        "    augument=False\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJbtAIeHeCrT"
      },
      "source": [
        "## TODO 2: Build your own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KdMBsGGvhCj",
        "outputId": "55891304-e239-4ec1-eaad-ba3e7c1ddc2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "base_model = tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Dense(4,activation='softmax')])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Functional)     (None, 7, 7, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 7,041,604\n",
            "Trainable params: 4,100\n",
            "Non-trainable params: 7,037,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HxIzhwIvi5y"
      },
      "source": [
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=config.lr)\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe-XtoMqvtjv"
      },
      "source": [
        "best_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.best_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "latest_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.latest_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=False, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", \n",
        "    mode=\"min\", \n",
        "    patience=10\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    patience=2,\n",
        "    factor=0.2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-9\n",
        ")\n",
        "\n",
        "callbacks_list = [\n",
        "    best_checkpoint,\n",
        "    latest_checkpoint,\n",
        "    reduce_lr,\n",
        "    early\n",
        "]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iK0nEptvwjF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPE5VOEDvxvF",
        "outputId": "6dcc7626-0fdb-4a4a-e6e3-dbc1f7b8710f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch= np.ceil(float(len(train_df)) / config.batch_size),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= np.ceil(float(len(val_df)) / config.batch_size),\n",
        "    epochs=config.epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=config.verbose\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-6ab872b8ec63>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/2\n",
            "173/211 [=======================>......] - ETA: 4:26 - loss: 0.0462"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e16cvL-vzX3"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZL5S7njv08p"
      },
      "source": [
        "test_generator = ImageGenerator.create(\n",
        "    test_df,\n",
        "    augument=False,\n",
        "    is_train=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzSFLGGSv4Pw"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AozVfrv7v5lU"
      },
      "source": [
        "pred_model = tf.keras.models.load_model(config.best_checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ib59cRYv67f"
      },
      "source": [
        "predict = pred_model.predict(test_generator,\n",
        "                             steps=np.ceil(float(len(test_df)) / config.batch_size),\n",
        "                             verbose=config.verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3n3VHeIv8s1"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJkEzXzv93d"
      },
      "source": [
        "predict = predict*256\n",
        "predict = predict.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9v4DqDLypfo"
      },
      "source": [
        "print(predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNfri3giv_MN"
      },
      "source": [
        "## Create submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPTGapqSwAmp"
      },
      "source": [
        "def clip(val, minval, maxval):\n",
        "    \"\"\"Clips a value between min and max (both including).\"\"\"\n",
        "    if val < minval:\n",
        "        return minval\n",
        "    elif val > maxval:\n",
        "        return maxval\n",
        "    else:\n",
        "        return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UokcsdmwCwN"
      },
      "source": [
        "# clip coordinates to be inside image\n",
        "for box in predict:\n",
        "    y0, x0, height, width = box\n",
        "    \n",
        "    y1 = y0 + height\n",
        "    x1 = x0 + width\n",
        "    \n",
        "    x0 = clip(x0, 0, 255)\n",
        "    x1 = clip(x1, 0, 255)\n",
        "    y0 = clip(y0, 0, 255)\n",
        "    y1 = clip(y1, 0, 255)\n",
        "    \n",
        "    if y0 > y1:\n",
        "        y0, y1 = y1, y0\n",
        "    if x0 > x1:\n",
        "        x0, x1 = x1, x0\n",
        "\n",
        "    height = y1 - y0\n",
        "    width = x1 - x0\n",
        "    \n",
        "    box[0] = y0\n",
        "    box[1] = x0\n",
        "    box[2] = height\n",
        "    box[3] = width"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQnCqy_OwEV9"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQCC-3LbwFc4"
      },
      "source": [
        "submissions = pd.DataFrame()\n",
        "submissions[\"ImageId\"] = test_df[\"ImageId\"]\n",
        "submissions[\"y0\"] = predict[:, 0]\n",
        "submissions[\"x0\"] = predict[:, 1]\n",
        "submissions[\"height\"] = predict[:, 2]\n",
        "submissions[\"width\"] = predict[:, 3]\n",
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMhtc81VWLv"
      },
      "source": [
        "image_path = \"/content/drive/My Drive/cat_face_exercise/images\"\n",
        "image_name = \"03227.jpg\"\n",
        "image = cv2.imread(image_path + \"/\" + image_name)\n",
        "cv2_imshow(image)\t\t\n",
        "img = image.copy()\n",
        "y0,x0,h,w =  33,\t24,\t50,\t147\n",
        "x1 = 256 - x0\n",
        "x2 = x0 + h\n",
        "y1 = y0 + w\n",
        "print(x0,y0,x1,y1,x2)\n",
        "cv2.rectangle(img,(x1 ,y0),(x2,y1),(0,255,0),4)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDE0xp0sbTLD"
      },
      "source": [
        "image_path = \"/content/drive/My Drive/cat_face_exercise/images/03227.jpg\"\n",
        "model = tf.keras.models.load_model(\"best.h5\")\n",
        "model.compile(loss='mean_squared_error',optimizer=tf.keras.optimizers.Adam(lr=config.lr))\n",
        "image = cv2.imread(image_path)\n",
        "img = cv2.resize(image,(224,224))\n",
        "img = img / 256\n",
        "img = np.reshape(img,[1,224,224,3])\n",
        "predict = model.predict(img)\n",
        "predict = predict*256\n",
        "predict = predict.astype(int)\n",
        "print(predict)\n",
        "for box in predict:\n",
        "  y0, x0, height, width = box\n",
        "  y1 = y0 + height\n",
        "  x1 = x0 + width\n",
        "  x0 = clip(x0, 0, 255)\n",
        "  x1 = clip(x1, 0, 255)\n",
        "  y0 = clip(y0, 0, 255)\n",
        "  y1 = clip(y1, 0, 255)\n",
        "        \n",
        "  if y0 > y1:\n",
        "    y0, y1 = y1, y0\n",
        "  if x0 > x1:\n",
        "    x0, x1 = x1, x0\n",
        "\n",
        "  height = y1 - y0\n",
        "  width = x1 - x0\n",
        "        \n",
        "  box[0] = y0\n",
        "  box[1] = x0\n",
        "  box[2] = height\n",
        "  box[3] = width\n",
        "      \n",
        "    \n",
        "cv2_imshow(image)\t\t\n",
        "image_show = image.copy()\n",
        "x1 = 256 - x0\n",
        "x2 = x0 + height\n",
        "y1 = y0 + width\n",
        "print(x0,y0,x1,y1,x2)\n",
        "cv2.rectangle(image_show,(x1,y0),(x2,y1),(0,255,0),4)\n",
        "cv2_imshow(image_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRiXf33wGtN"
      },
      "source": [
        "submissions.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUiHMp9cvmo8"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGfibS0DwIYF"
      },
      "source": [
        "## TODO 3: Visualize prediction\n",
        "\n",
        "You need to visualize predicted bounding box on given test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOAwpNvgwKFG"
      },
      "source": [
        "N = len(test_df)\n",
        "N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8ofDBBwLav"
      },
      "source": [
        "def draw_box(model, image_path):\n",
        "    \n",
        "    model = tf.keras.models.load_model(model)\n",
        "    model.compile(loss='mean_squared_error',\n",
        "        optimizer=tf.keras.optimizers.Adam(lr=config.lr)\n",
        "    )\n",
        "    image = cv2.imread(image_path)\n",
        "    img = cv2.resize(image,(224,224))\n",
        "    img = img / 256\n",
        "    img = np.reshape(img,[1,224,224,3])\n",
        "    predict = model.predict(img)\n",
        "    predict = predict*256\n",
        "    predict = predict.astype(int)\n",
        "    print(predict)\n",
        "    for box in predict:\n",
        "      y0, x0, height, width = box\n",
        "      \n",
        "      y1 = y0 + height\n",
        "      x1 = x0 + width\n",
        "      \n",
        "      x0 = clip(x0, 0, 255)\n",
        "      x1 = clip(x1, 0, 255)\n",
        "      y0 = clip(y0, 0, 255)\n",
        "      y1 = clip(y1, 0, 255)\n",
        "      \n",
        "      if y0 > y1:\n",
        "          y0, y1 = y1, y0\n",
        "      if x0 > x1:\n",
        "          x0, x1 = x1, x0\n",
        "\n",
        "      height = y1 - y0\n",
        "      width = x1 - x0\n",
        "      \n",
        "      box[0] = y0\n",
        "      box[1] = x0\n",
        "      box[2] = height\n",
        "      box[3] = width\n",
        "    \n",
        "    \n",
        "    cv2_imshow(image)\t\t\n",
        "    image_show = image.copy()\n",
        "    \n",
        "    x1 = 256 - x0\n",
        "    x2 = x0 + height\n",
        "    y1 = y0 + width\n",
        "    print(x0,y0,x1,y1,x2)\n",
        "    cv2.rectangle(image_show,(x1,y0),(x2,y1),(0,255,0),4)\n",
        "    cv2_imshow(image_show)\n",
        "    return\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5Zf8i6LQ1I"
      },
      "source": [
        "draw_box(config.best_checkpoint_path,\"/content/drive/My Drive/cat_face_exercise/images/03227.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwik0ciAwMh0"
      },
      "source": [
        "num_sample = 10\n",
        "\n",
        "for idx in range(num_sample):\n",
        "    idx = random.randint(0, N - 1)\n",
        "    image_name = test_df[\"ImageId\"].iloc[idx]\n",
        "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
        "    \n",
        "    draw_box(pred_model, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ6yc33uwObs"
      },
      "source": [
        "## TODO 4: Customize your model\n",
        "\n",
        "You need to build a model that can check if cat face exists in given images. If exists, then predict the cat face coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyFyzRoKwQS1"
      },
      "source": [
        "# TODO 4:\n",
        "check_model = tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "check_model.trainable = True\n",
        "model = tf.keras.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Dense(4,activation='soigmid')])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()\n",
        "\n",
        "base_model = tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Dense(4,activation='softmax')])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKjlzKaFwSau"
      },
      "source": [
        "# What to submit?\n",
        "\n",
        "Please send a .zip file to my email: thanglecao0412@gmail.com with the subject [VietAI Detection Exercise - Your name]. \n",
        "The .zip file includes\n",
        "- This notebook when you finish\n",
        "- Your submission file (.csv) on test dataset. Note that the submission file has the same format as **train.csv**\n",
        "- Your best model checkpoint"
      ]
    }
  ]
}