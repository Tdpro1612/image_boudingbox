{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat Face Localization Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UaB0jUXsy8j"
      },
      "source": [
        "# Cat Face Localization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_RFsb_cacFY"
      },
      "source": [
        "## Mounting to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAKtxD_pu-H3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyA6LEduasVA"
      },
      "source": [
        "##Check Colab GPU Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4brLgYDbFoa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tqRG_2-er5M"
      },
      "source": [
        "## Downloading dataset\n",
        "\n",
        "The original dataset can be found here. In the scope of this exercise, we use its cleaned version. The dataset contains:\n",
        "* train.csv : .csv file of $8996$ rows, containing image names and coordinates of cat faces in format (x0, y0, width, height)\n",
        "* test.csv : .csv file of $1000$ rows, containing image names\n",
        "* images/ : a folder contains $9996$ images with size of $256 \\times 256$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUs6p2SXfU3s"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmAn0UqkvLGx"
      },
      "source": [
        "TRAIN_FILE = \"/content/drive/My Drive/cat_face_exercise/train.csv\"\n",
        "TEST_FILE = \"/content/drive/My Drive/cat_face_exercise/test.csv\"\n",
        "IMAGE_DIR = \"/content/drive/My Drive/cat_face_exercise/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0zeIiPVvNjQ"
      },
      "source": [
        "df = pd.read_csv(TRAIN_FILE)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAP-z-aovQlZ"
      },
      "source": [
        "test_df = pd.read_csv(TEST_FILE)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U6AVlOYvSPG"
      },
      "source": [
        "train_df, val_df = train_test_split(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MekwqWVvWNv"
      },
      "source": [
        "print(len(df))\n",
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_WduMcSvXta"
      },
      "source": [
        "class Config:\n",
        "    \n",
        "    seed = 2020\n",
        "    \n",
        "    img_width = 256\n",
        "    img_height = 256\n",
        "    \n",
        "    num_classes = 4\n",
        "\n",
        "    batch_size = 32\n",
        "    epochs = 2    \n",
        "    lr = 1e-5\n",
        "    \n",
        "    verbose = 1\n",
        "    \n",
        "    best_checkpoint_path = 'best.h5'\n",
        "    latest_checkpoint_path = 'latest.h5'\n",
        "    \n",
        "config = Config()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnfTA-GBJqYl"
      },
      "source": [
        "## TODO 1: Data Loader\n",
        " You need to do the augmentation when loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DMNhaweJoaE"
      },
      "source": [
        "class ImageGenerator:\n",
        "    \n",
        "    def create(image_df, augument=True, is_train=True):\n",
        "        while True:\n",
        "            \n",
        "            if is_train:\n",
        "                image_df = shuffle(image_df, random_state=config.seed)\n",
        "                \n",
        "            for start in range(0, len(image_df), config.batch_size):\n",
        "                end = min(start + config.batch_size, len(image_df))\n",
        "                batch_images = []\n",
        "                X_train_batch = image_df.iloc[start:end]\n",
        "                \n",
        "                if is_train:\n",
        "                    batch_labels = np.zeros((len(X_train_batch), 4))\n",
        "                \n",
        "                for i in range(len(X_train_batch)):\n",
        "                    # load image\n",
        "                    image_path = os.path.join(IMAGE_DIR, X_train_batch.iloc[i]['ImageId'])\n",
        "                    image = cv2.imread(image_path)\n",
        "                    \n",
        "                    if is_train:\n",
        "                        x0 = X_train_batch.iloc[i]['x0']\n",
        "                        y0 = X_train_batch.iloc[i]['y0']\n",
        "                        w = X_train_batch.iloc[i]['width']\n",
        "                        h = X_train_batch.iloc[i]['height']\n",
        "                    \n",
        "                        # augment data\n",
        "                        if augument:\n",
        "                            # TODO 1: augmentation\n",
        "                            pass\n",
        "\n",
        "                        batch_labels[i][0] = y0 / 256\n",
        "                        batch_labels[i][1] = x0 / 256\n",
        "                        batch_labels[i][2] = h / 256\n",
        "                        batch_labels[i][3] = w / 256\n",
        "\n",
        "                    batch_images.append(image / 255)\n",
        "                    \n",
        "                if is_train:\n",
        "                    yield np.array(batch_images, np.float32), batch_labels\n",
        "                else:\n",
        "                    yield np.array(batch_images, np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPIzcM_Uvdx0"
      },
      "source": [
        "train_generator = ImageGenerator.create(\n",
        "    train_df,\n",
        "    augument=True\n",
        ")\n",
        "\n",
        "val_generator = ImageGenerator.create(\n",
        "    val_df,\n",
        "    augument=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJbtAIeHeCrT"
      },
      "source": [
        "## TODO 2: Build your own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KdMBsGGvhCj"
      },
      "source": [
        "base_model = tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "model = tf.keras.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Dense(4,activation='softmax')])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HxIzhwIvi5y"
      },
      "source": [
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=config.lr)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe-XtoMqvtjv"
      },
      "source": [
        "best_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.best_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "latest_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    config.latest_checkpoint_path, \n",
        "    monitor='val_loss', \n",
        "    verbose=1, \n",
        "    save_best_only=False, \n",
        "    save_weights_only=False,\n",
        "    mode='min'\n",
        "    \n",
        ")\n",
        "\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", \n",
        "    mode=\"min\", \n",
        "    patience=10\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    patience=2,\n",
        "    factor=0.2,\n",
        "    verbose=1,\n",
        "    min_lr=1e-9\n",
        ")\n",
        "\n",
        "callbacks_list = [\n",
        "    best_checkpoint,\n",
        "    latest_checkpoint,\n",
        "    reduce_lr,\n",
        "    early\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iK0nEptvwjF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPE5VOEDvxvF"
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch= np.ceil(float(len(train_df)) / config.batch_size),\n",
        "    validation_data=val_generator,\n",
        "    validation_steps= np.ceil(float(len(val_df)) / config.batch_size),\n",
        "    epochs=config.epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=config.verbose\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e16cvL-vzX3"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZL5S7njv08p"
      },
      "source": [
        "test_generator = ImageGenerator.create(\n",
        "    test_df,\n",
        "    augument=False,\n",
        "    is_train=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzSFLGGSv4Pw"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AozVfrv7v5lU"
      },
      "source": [
        "pred_model = tf.keras.models.load_model(config.best_checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ib59cRYv67f"
      },
      "source": [
        "predict = pred_model.predict(test_generator,\n",
        "                             steps=np.ceil(float(len(test_df)) / config.batch_size),\n",
        "                             verbose=config.verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3n3VHeIv8s1"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJkEzXzv93d"
      },
      "source": [
        "predict = predict*256\n",
        "predict = predict.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9v4DqDLypfo"
      },
      "source": [
        "print(predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNfri3giv_MN"
      },
      "source": [
        "## Create submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPTGapqSwAmp"
      },
      "source": [
        "def clip(val, minval, maxval):\n",
        "    \"\"\"Clips a value between min and max (both including).\"\"\"\n",
        "    if val < minval:\n",
        "        return minval\n",
        "    elif val > maxval:\n",
        "        return maxval\n",
        "    else:\n",
        "        return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UokcsdmwCwN"
      },
      "source": [
        "# clip coordinates to be inside image\n",
        "for box in predict:\n",
        "    y0, x0, height, width = box\n",
        "    \n",
        "    y1 = y0 + height\n",
        "    x1 = x0 + width\n",
        "    \n",
        "    x0 = clip(x0, 0, 255)\n",
        "    x1 = clip(x1, 0, 255)\n",
        "    y0 = clip(y0, 0, 255)\n",
        "    y1 = clip(y1, 0, 255)\n",
        "    \n",
        "    if y0 > y1:\n",
        "        y0, y1 = y1, y0\n",
        "    if x0 > x1:\n",
        "        x0, x1 = x1, x0\n",
        "\n",
        "    height = y1 - y0\n",
        "    width = x1 - x0\n",
        "    \n",
        "    box[0] = y0\n",
        "    box[1] = x0\n",
        "    box[2] = height\n",
        "    box[3] = width"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQnCqy_OwEV9"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQCC-3LbwFc4"
      },
      "source": [
        "submissions = pd.DataFrame()\n",
        "submissions[\"ImageId\"] = test_df[\"ImageId\"]\n",
        "submissions[\"y0\"] = predict[:, 0]\n",
        "submissions[\"x0\"] = predict[:, 1]\n",
        "submissions[\"height\"] = predict[:, 2]\n",
        "submissions[\"width\"] = predict[:, 3]\n",
        "submissions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvRiXf33wGtN"
      },
      "source": [
        "submissions.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGfibS0DwIYF"
      },
      "source": [
        "## TODO 3: Visualize prediction\n",
        "\n",
        "You need to visualize predicted bounding box on given test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUiHMp9cvmo8"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOAwpNvgwKFG"
      },
      "source": [
        "N = len(test_df)\n",
        "N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8ofDBBwLav"
      },
      "source": [
        "def draw_box(model, image_path):\n",
        "    \n",
        "    model = tf.keras.models.load_model(model)\n",
        "    model.compile(loss='mean_squared_error',\n",
        "        optimizer=tf.keras.optimizers.Adam(lr=config.lr)\n",
        "    )\n",
        "    image = cv2.imread(image_path)\n",
        "    img = cv2.resize(image,(224,224))\n",
        "    img = img / 256\n",
        "    img = np.reshape(img,[1,224,224,3])\n",
        "    predict = model.predict(img)\n",
        "    predict = predict*256\n",
        "    predict = predict.astype(int)\n",
        "    print(predict)\n",
        "    for box in predict:\n",
        "      y0, x0, height, width = box\n",
        "      \n",
        "      y1 = y0 + height\n",
        "      x1 = x0 + width\n",
        "      \n",
        "      x0 = clip(x0, 0, 255)\n",
        "      x1 = clip(x1, 0, 255)\n",
        "      y0 = clip(y0, 0, 255)\n",
        "      y1 = clip(y1, 0, 255)\n",
        "      \n",
        "      if y0 > y1:\n",
        "          y0, y1 = y1, y0\n",
        "      if x0 > x1:\n",
        "          x0, x1 = x1, x0\n",
        "\n",
        "      height = y1 - y0\n",
        "      width = x1 - x0\n",
        "      \n",
        "      box[0] = y0\n",
        "      box[1] = x0\n",
        "      box[2] = height\n",
        "      box[3] = width\n",
        "    \n",
        "    \n",
        "    cv2_imshow(image)\t\t\n",
        "    image_show = image.copy()\n",
        "    \n",
        "    x1 = 256 - x0\n",
        "    x2 = x0 + height\n",
        "    y1 = y0 + width\n",
        "    print(x0,y0,x1,y1,x2)\n",
        "    cv2.rectangle(image_show,(x1,y0),(x2,y1),(0,255,0),4)\n",
        "    cv2_imshow(image_show)\n",
        "    return\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5Zf8i6LQ1I"
      },
      "source": [
        "draw_box(config.best_checkpoint_path,\"/content/drive/My Drive/cat_face_exercise/images/06239.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwik0ciAwMh0"
      },
      "source": [
        "num_sample = 10\n",
        "\n",
        "for idx in range(num_sample):\n",
        "    idx = random.randint(0, N - 1)\n",
        "    image_name = test_df[\"ImageId\"].iloc[idx]\n",
        "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
        "    print(image_path)\n",
        "    draw_box(config.best_checkpoint_path, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ6yc33uwObs"
      },
      "source": [
        "## TODO 4: Customize your model\n",
        "\n",
        "You need to build a model that can check if cat face exists in given images. If exists, then predict the cat face coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyFyzRoKwQS1"
      },
      "source": [
        "# TODO 4:\n",
        "check_model = tf.keras.applications.DenseNet121(include_top=False,weights=\"imagenet\",input_shape=(224,224,3))\n",
        "check_model.trainable = True\n",
        "model = tf.keras.Sequential([base_model,tf.keras.layers.GlobalAveragePooling2D(),tf.keras.layers.Dense(4,activation='soigmid')])\n",
        "\n",
        "# Print out model summary\n",
        "model.summary()\n",
        "# nếu là mèo thì draw_box(model, image_path)\n",
        "# nếu không phải mèo thì thôi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}